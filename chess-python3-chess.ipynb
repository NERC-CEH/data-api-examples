{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chess webservice examples\n",
    "\n",
    "This notebook shows examples of using the CHESS-met data api to acess the [CHESS-met dataset](https://catalogue.ceh.ac.uk/documents/2ab15bf0-ad08-415c-ba64-831168be7293).  Please see [CHESS-met dataset](https://catalogue.ceh.ac.uk/documents/2ab15bf0-ad08-415c-ba64-831168be7293) for further information about this dataset.\n",
    "\n",
    "Full documentation for the api is [here](https://data-eidc.ceh.ac.uk/1.0/2ab15bf0-ad08-415c-ba64-831168be7293/ui/).\n",
    "\n",
    "**Note:** this workbook was developed using the [SciPy-notebook](https://hub.docker.com/r/jupyter/scipy-notebook) docker image from DockerHub.  If you have Docker run `docker run -p 8888:8888 jupyter/scipy-notebook:latest` to get a Jupyter notebook with all needed python dependencies already installed.\n",
    "\n",
    "The following examples demonstrate all the api endpoints available, which are:\n",
    "- reduceTime: summarises across time to produce a raster layer for a given region and date range\n",
    "- reduceSpace: summarises across a region to produce single daily values for that region\n",
    "- timeSeries: provides daily values for a point and date range\n",
    "- subset: download a subset of the Chess data as a netcdf file\n",
    "\n",
    "All examples use the surface temperature (abbreviated to `tas`) environmental variable, but there are 7 other variables to choose from (see [documentation](https://data-eidc.ceh.ac.uk/1.0/2ab15bf0-ad08-415c-ba64-831168be7293/ui/)).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters and provide token\n",
    "Start by setting the parameters needed by the `request`.  One of these parameters is an authentication token available from [https://data-eidc.ceh.ac.uk/authentication](https://data-eidc.ceh.ac.uk/authentication).  Once you have this token, run the cell below and paste it into the box as prompted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "domain = 'https://data-eidc.ceh.ac.uk'\n",
    "version = '1.0'\n",
    "chess_dataset_identifier = '2ab15bf0-ad08-415c-ba64-831168be7293'\n",
    "\n",
    "api_url_base = f'{domain}/{version}/{chess_dataset_identifier}/'\n",
    "\n",
    "api_token = input('Paste your token (eg ff0fcc12db8efa2d71ab79e36335ca6c):  ')\n",
    "# api_token = 'ff0fcc12db8efa2d71ab79e36335ca6c'\n",
    "\n",
    "headers = {'Authorization': f'Bearer {api_token}'}\n",
    "\n",
    "chess_variable = 'tas' #All examples use 'tas', which is the 'temperature at surface' in degrees Kelvin\n",
    "\n",
    "print('Parameters have been set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reduceTime endpoint\n",
    "\n",
    "The reduceTime endpoint subsets a Chess variable by space and time and averages (or min, max or count) across the time axis to produce a 2-d grid.  It returns data as json using the covjson format (see https://www.w3.org/TR/covjson-overview/ and https://covjson.org/)\n",
    "\n",
    "In the example below, a bounding box around the Lake District is provided together with a date range, variable name (tas) and metric we want calcuated (mean).  So in this example, for each 1km square within the bounding box, we are asking for the mean tas value across all days within our date range.\n",
    "\n",
    "The data are extracted from the response, put into a 2-d grid and plotted.  Also it is output to an asciigrid that can be viewed in a GIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# I've defined a bounding box of about 40x40km centred on Scafell Pike: 321495,507361\n",
    "payload = {\n",
    "    'dateFrom': '1961-01-01',\n",
    "    'dateTo': '1962-01-01',\n",
    "    'north': 547361,\n",
    "    'south': 467361,\n",
    "    'east': 361495,\n",
    "    'west': 281495,\n",
    "    'metric': 'mean'\n",
    "}\n",
    "\n",
    "# A function that requests and returns the data from the Chess api\n",
    "def get_means_json():\n",
    "    headers['Accept'] = 'application/json'\n",
    "    api_url = f'{api_url_base}reduceTime/{chess_variable}'\n",
    "    resp = requests.get(api_url, headers=headers, params=payload)\n",
    "    if resp.status_code != 200:\n",
    "        raise RuntimeError(f'GET /reduceTime/ {resp.status_code}')\n",
    "    return resp\n",
    "\n",
    "#get the data from the api and pull out the axis and values\n",
    "resp = get_means_json()\n",
    "# uncomment to see the json data returned, this is in covJson format: https://www.w3.org/TR/covjson-overview/ and https://covjson.org/\n",
    "# print(json.dumps(resp.json(), indent=2))\n",
    "resp_json = resp.json()\n",
    "x_axis = resp_json['domain']['axes']['x']['values']\n",
    "y_axis = resp_json['domain']['axes']['y']['values']\n",
    "values = resp_json['ranges']['variable']['values']\n",
    "\n",
    "# change the no data value (-99999) to python's not-a-number value (nan)\n",
    "nodatavalue = -99999\n",
    "values = np.array(values)\n",
    "values[values==nodatavalue]=np.nan\n",
    "\n",
    "# since the data are in covjson format, they are in one big long list\n",
    "# reshape this into a 2-d numpy array of values, rotate and flip to get into correct orientation\n",
    "data = np.array(values).reshape(len(x_axis),len(y_axis)).transpose(1,0)\n",
    "data = np.flip(data)\n",
    "data = np.flip(data, 1)\n",
    "\n",
    "# display as a map\n",
    "plt.imshow(data, interpolation='nearest')\n",
    "\n",
    "# save as ascii grid that can be opened in qgis (would be nice to have this directly from api as a format option)\n",
    "filename = 'asciigrid.csv'\n",
    "data[np.isnan(data)]=nodatavalue\n",
    "np.savetxt(filename, data, delimiter=' ', fmt='%6.5f')\n",
    "cellsize = x_axis[1] - x_axis[0]\n",
    "xllcorner = x_axis[0] - cellsize\n",
    "yllcorner = y_axis[0] - cellsize\n",
    "header = f'ncols {len(x_axis)}\\nnrows {len(y_axis)}\\nxllcorner {xllcorner}\\nyllcorner {yllcorner}\\ncellsize {cellsize}\\nnodata_value {nodatavalue}\\n'\n",
    "with open(filename, 'r+') as f:\n",
    "    content = f.read()\n",
    "    f.seek(0,0)\n",
    "    f.write(header + content)\n",
    "\n",
    "print('finished - open asciigrid.csv in your GIS to view as a map - it is on the British National Grid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reduceSpace webservice\n",
    "\n",
    "This averages across 1km grid squares for a region (user defined bounding box) for each day in a date range.\n",
    "Essentially it is a timeseries for a bounding box of any size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# I've defined a bounding box of about 40x40km centred on Scafell Pike: 321495,507361\n",
    "north = 547361\n",
    "south = 467361\n",
    "east = 361495\n",
    "west = 281495\n",
    "dateFrom = '1961-01-01'\n",
    "dateTo = '1962-01-01'\n",
    "metric = 'mean'\n",
    "payload = {\n",
    "    'dateFrom': dateFrom,\n",
    "    'dateTo': dateTo,\n",
    "    'north': north,\n",
    "    'south': south,\n",
    "    'east': east,\n",
    "    'west': west,\n",
    "    'metric': metric\n",
    "}\n",
    "\n",
    "# A function that requests and returns the data from the Chess api\n",
    "def get_means_json():\n",
    "    headers['Accept'] = 'application/json'\n",
    "    api_url = f'{api_url_base}reduceSpace/{chess_variable}'\n",
    "    resp = requests.get(api_url, headers=headers, params=payload)\n",
    "    if resp.status_code != 200:\n",
    "        raise RuntimeError(f'GET /reduceTime/ {resp.status_code}')\n",
    "    return resp\n",
    "\n",
    "#get the data from the api and pull out the axis and values\n",
    "resp = get_means_json()\n",
    "# uncomment to see the json data returned, this is in covJson format: https://www.w3.org/TR/covjson-overview/ and https://covjson.org/\n",
    "# print(json.dumps(resp.json(), indent=2))\n",
    "resp_json = resp.json()\n",
    "values = resp_json['properties']['values']\n",
    "print(f'These are the {metric} daily {chess_variable} values for your bounding box ({north}, {south}, {east}, {west}) across the date range {dateFrom} to {dateTo}:')\n",
    "for val in values:\n",
    "    print(f'{val[\"date\"]} {val[\"mean\"]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## timeSeries webservice\n",
    "The time series webservice gets daily values for a point location for a date range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_timeseries(easting, northing, dateFrom, dateTo):\n",
    "    payload = {\n",
    "        'dateFrom': dateFrom,\n",
    "        'dateTo': dateTo,\n",
    "        'easting': easting,\n",
    "        'northing': northing\n",
    "    }\n",
    "    print('Getting timeseries data...\\n')\n",
    "    headers['Accept'] = 'application/json'\n",
    "    api_url = f'{api_url_base}timeseries/{chess_variable}'\n",
    "    resp = requests.get(api_url, headers=headers, params=payload)\n",
    "    if resp.status_code != 200:\n",
    "        print(resp.text)\n",
    "        raise RuntimeError(f'GET /timeSeries/ {resp.status_code}')\n",
    "    return resp.json()\n",
    "    \n",
    "dateFrom = '1961-01-01'\n",
    "dateTo = '1965-12-31'\n",
    "easting = 290567\n",
    "northing = 300123\n",
    "timeseries_json = get_timeseries(easting, northing, dateFrom, dateTo)\n",
    "print(f'These are the daily {chess_variable} values for your point ({easting}, {northing}) across the date range {dateFrom} to {dateTo}:')\n",
    "\n",
    "# Turn the json into a flat table and force the date to be a 'real' date type ready for any timeseries analysis or plotting\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "def to_table():\n",
    "    timeseries = json_normalize(timeseries_json)\n",
    "    timeseries['date'] = pd.to_datetime(timeseries['date'])\n",
    "    return timeseries\n",
    "timeseries_table = to_table()\n",
    "print(timeseries_table)\n",
    "\n",
    "# Plot it and calculate some statistics\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "plt.xticks(rotation=90)\n",
    "plt.plot(timeseries_table['date'], timeseries_table['value'])\n",
    "plt.title(f'Mean daily temperatures for the coordinate: {easting}, {northing} from {dateFrom} to {dateTo}')\n",
    "print('\\nHere are some statistics calculated across the data, followed by a chart of the data')\n",
    "print(f'Mean: {timeseries_table[\"value\"].mean()}')\n",
    "print(f'Std: {timeseries_table[\"value\"].std()}')\n",
    "print(f'Min: {timeseries_table[\"value\"].min()}')\n",
    "print(f'Max: {timeseries_table[\"value\"].max()}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subset webservice\n",
    "The `subset` webservice provides a netcdf download of one Chess variable for a spatial-temporal filter.\n",
    "\n",
    "The following two code blocks demonstrate firstly how to get a subset of Chess data and save as a netcdf file.  Then how to plot daily maps for the chess variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the netcdf subset for your region and date range and save as a temporary netcdf file.\n",
    "\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "payload = {\n",
    "    'dateFrom': '1961-01-01',\n",
    "    'dateTo': '1961-02-28',\n",
    "    'north': 250000,\n",
    "    'south': 100000,\n",
    "    'east': 650000,\n",
    "    'west': 500000\n",
    "}\n",
    "   \n",
    "def get_netcdf():\n",
    "    print('Getting data...')\n",
    "    headers['Content-Type'] = 'application/x-netcdf'\n",
    "    api_url = f'{api_url_base}subset/{chess_variable}'\n",
    "    resp = requests.get(api_url, headers=headers, params=payload, stream=True)\n",
    "    if resp.status_code != 200:\n",
    "        raise RuntimeError(f'GET /reduceTime/ {resp.status_code}')\n",
    "    targetfile = tempfile.NamedTemporaryFile(delete=False, suffix='.nc')\n",
    "    print(targetfile.name)\n",
    "    with targetfile as output:\n",
    "        output.write(resp.content)\n",
    "    print(f'File location: {targetfile.name}')\n",
    "    print(f'File size: {os.path.getsize(targetfile.name)}')\n",
    "    return targetfile.name\n",
    "\n",
    "subset_filename = get_netcdf()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now do something with the data you retrieved - in this case show daily maps for each date in the dataset.\n",
    "# This has some hefty imports and that may need adding to your environment\n",
    "\n",
    "%pip install netcdf4\n",
    "import netCDF4\n",
    "%pip install xarray\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "    \n",
    "def netcdf_maps():\n",
    "    xr_dataset = xr.open_dataset(subset_filename)\n",
    "    vmax = xr_dataset.max()['tas'].values\n",
    "    vmin = xr_dataset.min()['tas'].values\n",
    "    nrows = divmod(len(xr_dataset.time), 3)[0] + 1\n",
    "    fig_height = nrows * 4\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=3, figsize=(16, fig_height))\n",
    "    for i, date in enumerate(xr_dataset.coords['time']):\n",
    "        x, y = divmod(i, 3)\n",
    "        xr_dataset['tas'].sel(time=date).plot.pcolormesh(\n",
    "            ax=axes[x, y], vmin=vmin, vmax=vmax, cmap='Spectral_r',\n",
    "            add_colorbar=True, extend='both', add_labels=False)\n",
    "        axes[x, y].set_title(str(date.values)[:10])\n",
    "    for ax in axes.flat:\n",
    "        ax.axes.get_xaxis().set_ticklabels([])\n",
    "        ax.axes.get_yaxis().set_ticklabels([])\n",
    "        ax.axes.axis('tight')\n",
    "        ax.set_xlabel('')\n",
    "    plt.tight_layout()\n",
    "    fig.suptitle('Surface Air Temperature (K)', fontsize=16, y=1.02)\n",
    "netcdf_maps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
